{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## CTWDoc2vec: TFIDF Weighted Doc2vec (Centred form, Scaled idf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def l2_normalize(x):\n",
    "    \"\"\"\n",
    "    L2 Normalization\n",
    "    \"\"\"\n",
    "    # Calculate the modulus of x\n",
    "    x_norm = math.sqrt(sum([xi**2 for xi in x]))\n",
    "    # Return the normalized vector\n",
    "    return [xi / x_norm for xi in x]\n",
    "\n",
    "def tfidf_vectorizer(corpus, smooth_idf=True):\n",
    "    \"\"\"\n",
    "    Calculate the TFIDF value\n",
    "    \"\"\"\n",
    "    vectorizer = CountVectorizer()\n",
    "    # Count the number of times each word appears in all documents\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    # Get all text keywords in the bag of words\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "    # Number of documents\n",
    "    n = X.shape[0]\n",
    "    # Matrix for storing TFIDF results\n",
    "    tfidf_matrix = []\n",
    "    # Iterate each document and calculate the TFIDF value\n",
    "    for i in range(n):\n",
    "        # Get the vector representation of the i-th document\n",
    "        row = X[i].toarray()[0]\n",
    "        # List of storing tf values\n",
    "        tf_scores = []\n",
    "        # List of storing idf values\n",
    "        idf_scores = []\n",
    "        # List of storing TFIDF values\n",
    "        tfidf_scores = []\n",
    "        # Iterate each keyword and calculate the TFIDF value\n",
    "        for j, word in enumerate(words):\n",
    "            # Calculate tf value\n",
    "            tf = row[j] / sum(row)\n",
    "            # Calculate df value\n",
    "            df = X[:, j].count_nonzero()\n",
    "            # Calculate idf value, with smooth_idf (default) or without smooth_idf\n",
    "            if smooth_idf:\n",
    "                idf = math.log((1 + n) / (1 + df)) + 1\n",
    "            else:\n",
    "                idf = math.log(n / df) + 1\n",
    "            # Store tf value in a list\n",
    "            tf_scores.append(tf)\n",
    "            # Store idf value in a list\n",
    "            idf_scores.append(idf)\n",
    "        # Min-max normalize idf to (0, 1)\n",
    "        for j, idf in enumerate(idf_scores):\n",
    "            idf_scores[j] = (idf - min(idf_scores)) / (max(idf_scores) - min(idf_scores))\n",
    "        # Calculate the TFIDF value\n",
    "        for j in range(len(tf_scores)):\n",
    "            tfidf_scores.append(tf_scores[j] * idf_scores[j])\n",
    "        # L2 normalize the tfidf_scores vector: l2_normalize(tfidf_scores)\n",
    "        # Store the list of TFIDF values for each document in the matrix\n",
    "        tfidf_matrix.append(l2_normalize(tfidf_scores))\n",
    "    return words, np.array(tfidf_matrix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def tfidf_centre(corpus, smooth_idf=True):\n",
    "    \"\"\"\n",
    "    Calculate the TFIDF_centre value\n",
    "    \"\"\"\n",
    "    vectorizer = CountVectorizer()\n",
    "    # Count the number of times each word appears in all documents\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    # Get all text keywords in the bag of words\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "    # Number of documents\n",
    "    n = X.shape[0]\n",
    "    # List of storing tf_centre values\n",
    "    tf_centre_scores = []\n",
    "    # List of storing idf values\n",
    "    idf_scores = []\n",
    "    # List of storing TFIDF_centre values\n",
    "    tfidf_centre_list = []\n",
    "    for j, word in enumerate(words):\n",
    "        # Calculate tf_centre value\n",
    "        tf_centre = X[:, j].sum() / X.sum()\n",
    "        # Calculate df value\n",
    "        df = X[:, j].count_nonzero()\n",
    "        # Calculate idf value, with smooth_idf (default) or without smooth_idf\n",
    "        if smooth_idf:\n",
    "            idf = math.log((1 + n) / (1 + df)) + 1\n",
    "        else:\n",
    "            idf = math.log(n / df) + 1\n",
    "        # Store tf_centre value in a list\n",
    "        tf_centre_scores.append(tf_centre)\n",
    "        # Store idf value in a list\n",
    "        idf_scores.append(idf)\n",
    "    # Min-max normalize idf to (0, 1)\n",
    "    for j, idf in enumerate(idf_scores):\n",
    "        idf_scores[j] = (idf - min(idf_scores)) / (max(idf_scores) - min(idf_scores))\n",
    "    # Calculate the TFIDF_centre value\n",
    "    for j in range(len(tf_centre_scores)):\n",
    "        tfidf_centre_list.append(tf_centre_scores[j] * idf_scores[j])\n",
    "    return np.array(tfidf_centre_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"The quick brown fox is very agile\",\n",
    "    \"The quick brown fox is very smart\",\n",
    "    \"The quick brown fox is very quick\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agile' 'brown' 'dog' 'fox' 'is' 'jumps' 'lazy' 'over' 'quick' 'smart'\n",
      " 'the' 'very']\n",
      "[[0.         0.         0.37220553 0.19423228 0.         0.37220553\n",
      "  0.37220553 0.37220553 0.19423228 0.         0.60860481 0.        ]\n",
      " [0.52555488 0.         0.         0.27425634 0.33545487 0.\n",
      "  0.         0.         0.27425634 0.         0.42967555 0.52555488]\n",
      " [0.         0.         0.         0.27425634 0.33545487 0.\n",
      "  0.         0.         0.27425634 0.52555488 0.42967555 0.52555488]\n",
      " [0.         0.         0.         0.28146379 0.34427062 0.\n",
      "  0.         0.         0.56292758 0.         0.44096741 0.53936645]]\n"
     ]
    }
   ],
   "source": [
    "words, tfidf_scores = tfidf_vectorizer(documents)\n",
    "print(words)\n",
    "print(tfidf_scores)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03333333 0.         0.03333333 0.06957886 0.0638287  0.03333333\n",
      " 0.03333333 0.03333333 0.08697358 0.03333333 0.13626092 0.1       ]\n"
     ]
    }
   ],
   "source": [
    "tfidf_centre_scores = tfidf_centre(documents)\n",
    "print(tfidf_centre_scores)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison with sklearn results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Creating a TF-IDF vectorizer by TfidfVectorizer()\n",
    "vectorizer_tfidf = TfidfVectorizer()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Vectorize the data set\n",
    "vectorized_documents = vectorizer_tfidf.fit_transform(documents)\n",
    "vectorized_documents_list = vectorized_documents.toarray()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.21472541, 0.41147631, 0.21472541, 0.        ,\n        0.41147631, 0.41147631, 0.41147631, 0.21472541, 0.        ,\n        0.42945081, 0.        ],\n       [0.58680608, 0.30621975, 0.        , 0.30621975, 0.37455072,\n        0.        , 0.        , 0.        , 0.30621975, 0.        ,\n        0.30621975, 0.37455072],\n       [0.        , 0.30621975, 0.        , 0.30621975, 0.37455072,\n        0.        , 0.        , 0.        , 0.30621975, 0.58680608,\n        0.30621975, 0.37455072],\n       [0.        , 0.3163518 , 0.        , 0.3163518 , 0.38694366,\n        0.        , 0.        , 0.        , 0.63270359, 0.        ,\n        0.3163518 , 0.38694366]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_documents_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
