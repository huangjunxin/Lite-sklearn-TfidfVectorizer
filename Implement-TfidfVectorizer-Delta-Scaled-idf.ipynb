{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## DTWDoc2vec: TFIDF Weighted Doc2vec (Delta form, Scaled idf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def l2_normalize(x):\n",
    "    \"\"\"\n",
    "    L2 Normalization\n",
    "    \"\"\"\n",
    "    # Calculate the modulus of x\n",
    "    x_norm = math.sqrt(sum([xi**2 for xi in x]))\n",
    "    # Return the normalized vector\n",
    "    return [xi / x_norm for xi in x]\n",
    "\n",
    "def tfidf_delta_vectorizer(corpus, smooth_idf=True):\n",
    "    \"\"\"\n",
    "    Calculate the TFIDF_delta value\n",
    "    \"\"\"\n",
    "    vectorizer = CountVectorizer()\n",
    "    # Count the number of times each word appears in all documents\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    # Get all text keywords in the bag of words\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "    # Number of documents\n",
    "    n = X.shape[0]\n",
    "    # Matrix for storing TFIDF results\n",
    "    tfidf_matrix = []\n",
    "    # Iterate each document and calculate the TFIDF value\n",
    "    for i in range(n):\n",
    "        # Get the vector representation of the i-th document\n",
    "        row = X[i].toarray()[0]\n",
    "        # List of storing delta values\n",
    "        delta_scores = []\n",
    "        # List of storing idf values\n",
    "        idf_scores = []\n",
    "        # List of storing TFIDF values\n",
    "        tfidf_scores = []\n",
    "        # Iterate each keyword and calculate the TFIDF value\n",
    "        for j, word in enumerate(words):\n",
    "            # Calculate delta value (delta = tf - tf_centre)\n",
    "            delta = row[j] / sum(row) - X[:, j].sum() / X.sum()\n",
    "            # Calculate df value\n",
    "            df = X[:, j].count_nonzero()\n",
    "            # Calculate idf value, with smooth_idf (default) or without smooth_idf\n",
    "            if smooth_idf:\n",
    "                idf = math.log((1 + n) / (1 + df)) + 1\n",
    "            else:\n",
    "                idf = math.log(n / df) + 1\n",
    "            # Store delta value in a list\n",
    "            delta_scores.append(delta)\n",
    "            # Store idf value in a list\n",
    "            idf_scores.append(idf)\n",
    "        # Min-max normalize idf to (0, 1)\n",
    "        for j, idf in enumerate(idf_scores):\n",
    "            idf_scores[j] = (idf - min(idf_scores)) / (max(idf_scores) - min(idf_scores))\n",
    "        # Calculate the TFIDF_delta value\n",
    "        for j in range(len(delta_scores)):\n",
    "            tfidf_scores.append(delta_scores[j] * idf_scores[j])\n",
    "        # L2 normalize the tfidf_scores vector: l2_normalize(tfidf_scores)\n",
    "        # Store the list of TFIDF values for each document in the matrix\n",
    "        tfidf_matrix.append(l2_normalize(tfidf_scores))\n",
    "    return words, np.array(tfidf_matrix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"The quick brown fox is very agile\",\n",
    "    \"The quick brown fox is very smart\",\n",
    "    \"The quick brown fox is very quick\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agile' 'brown' 'dog' 'fox' 'is' 'jumps' 'lazy' 'over' 'quick' 'smart'\n",
      " 'the' 'very']\n",
      "[[-0.15976266 -0.          0.37277955 -0.05558052 -0.30592331  0.37277955\n",
      "   0.37277955  0.37277955 -0.13895131 -0.15976266  0.21769408 -0.47928799]\n",
      " [ 0.76135244  0.         -0.23171596  0.03454829  0.19015881 -0.23171596\n",
      "  -0.23171596 -0.23171596 -0.08637071 -0.23171596 -0.13531642  0.29792052]\n",
      " [-0.23171596  0.         -0.23171596  0.03454829  0.19015881 -0.23171596\n",
      "  -0.23171596 -0.23171596 -0.08637071  0.76135244 -0.13531642  0.29792052]\n",
      " [-0.28673143  0.         -0.28673143  0.04275096  0.23530752 -0.28673143\n",
      "  -0.28673143 -0.28673143  0.53438698 -0.28673143 -0.16744409  0.36865469]]\n"
     ]
    }
   ],
   "source": [
    "words, tfidf_delta_scores = tfidf_delta_vectorizer(documents)\n",
    "print(words)\n",
    "print(tfidf_delta_scores)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison with sklearn results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Creating a TF-IDF vectorizer by TfidfVectorizer()\n",
    "vectorizer_tfidf = TfidfVectorizer()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Vectorize the data set\n",
    "vectorized_documents = vectorizer_tfidf.fit_transform(documents)\n",
    "vectorized_documents_list = vectorized_documents.toarray()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.21472541, 0.41147631, 0.21472541, 0.        ,\n        0.41147631, 0.41147631, 0.41147631, 0.21472541, 0.        ,\n        0.42945081, 0.        ],\n       [0.58680608, 0.30621975, 0.        , 0.30621975, 0.37455072,\n        0.        , 0.        , 0.        , 0.30621975, 0.        ,\n        0.30621975, 0.37455072],\n       [0.        , 0.30621975, 0.        , 0.30621975, 0.37455072,\n        0.        , 0.        , 0.        , 0.30621975, 0.58680608,\n        0.30621975, 0.37455072],\n       [0.        , 0.3163518 , 0.        , 0.3163518 , 0.38694366,\n        0.        , 0.        , 0.        , 0.63270359, 0.        ,\n        0.3163518 , 0.38694366]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_documents_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
